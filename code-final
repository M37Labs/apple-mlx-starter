import json
import os
import random
from typing import Dict, List, Tuple

import numpy as np
from datasets import load_dataset

# Constants
MODEL_NAME = "mlx-community/Mistral-7B-Instruct-v0.2-4bit"
MLX_QUANTIZE_MODEL = 'phi2_quantized'
OUTPUT_DIR = "m37labs-PI1"
TRAIN_DATA_DIR = "train_data"
VALIDATION_SPLIT = 0.1
TEST_SPLIT = 0.1


def download_hf_dataset() -> List[Dict[str, str]]:
    """Download the Hugging Face dataset using its actual split name ('data')."""
    print("Downloading dataset from Hugging Face...")
    dataset = load_dataset("M37labsorg/Legal_Information", split="data", download_mode="force_redownload")
    return list(dataset)


def extract_legal_samples(data: List[Dict]) -> List[Dict[str, str]]:
    """Format dataset into MLX-LM prompt format using Instruction and Response."""
    samples = []
    for entry in data:
        question = entry.get("Instruction", "").strip()
        answer = entry.get("Response", "").strip()
        context = "You are a helpful legal assistant answering legal questions."

        if question and answer:
            formatted_text = {
                "text": f"### system: {context}\n\n### user: {question}\n\n### assistant: {answer}"
            }
            samples.append(formatted_text)
    return samples


def split_data(samples: List[Dict[str, str]], val_split: float, test_split: float) -> Tuple[List, List, List]:
    """Split data into train, val, and test sets."""
    random.shuffle(samples)
    total = len(samples)
    val_size = int(total * val_split)
    test_size = int(total * test_split)

    test_samples = samples[:test_size]
    val_samples = samples[test_size:test_size + val_size]
    train_samples = samples[test_size + val_size:]
    return train_samples, val_samples, test_samples


def save_samples_as_jsonl(samples: List[Dict[str, str]], output_dir: str, filename: str):
    """Save formatted samples to JSONL."""
    os.makedirs(output_dir, exist_ok=True)
    file_path = os.path.join(output_dir, filename)
    print(f"Saving {len(samples)} samples to {file_path}")
    with open(file_path, "w", encoding="utf-8") as f:
        for sample in samples:
            f.write(json.dumps(sample) + "\n")


def main():
    random.seed(42)
    np.random.seed(42)

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(TRAIN_DATA_DIR, exist_ok=True)

    # Step 1: Download & extract
    raw_data = download_hf_dataset()
    print(f"Total raw samples: {len(raw_data)}")

    # Step 2: Format to prompt format
    samples = extract_legal_samples(raw_data)
    print(f"Formatted {len(samples)} valid samples.")

    # Step 3: Split into train/val/test
    train, val, test = split_data(samples, VALIDATION_SPLIT, TEST_SPLIT)

    # Step 4: Save as jsonl
    save_samples_as_jsonl(train, TRAIN_DATA_DIR, "train.jsonl")
    save_samples_as_jsonl(val, TRAIN_DATA_DIR, "valid.jsonl")
    save_samples_as_jsonl(test, TRAIN_DATA_DIR, "test.jsonl")

    # Step 5: Training instructions
    print("\n✅ Dataset ready for MLX-LM fine-tuning.")
    print("\n➡️ Quantize model:")
    print(f"""python3 -m mlx_lm convert \\
    --hf-path {MODEL_NAME} \\
    --mlx-path {MLX_QUANTIZE_MODEL} \\
    -q""")

    print("\n➡️ Train with LoRA:")
    print(f"""python3 -m mlx_lm lora \\
    --model {MLX_QUANTIZE_MODEL} \\
    --train \\
    --data {TRAIN_DATA_DIR} \\
    --num-layers 8 \\
    --batch-size 2 \\
    --iters 100 \\
    --learning-rate 5e-5 \\
    --steps-per-report 10 \\
    --adapter-path {OUTPUT_DIR} \\
    --fine-tune-type lora""")

    print("\n➡️ Evaluate trained model:")
    print(f"""python3 -m mlx_lm lora \\
    --model {MLX_QUANTIZE_MODEL} \\
    --adapter-path {OUTPUT_DIR} \\
    --test \\
    --data {TRAIN_DATA_DIR} \\
    --test-batches 5""")


if __name__ == "__main__":
    main()
